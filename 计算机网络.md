#### 1.什么是网络协议，为什么要对网络协议分层
    网络协议是计算机在通信过程中要遵循的一些约定好的规则。
    网络分层的原因：
    易于实现和维护，因为各层之间是独立的，层与层之间不会收到影响。有利于标准化的制定
#### 2.计算机网络的各层协议及作用
    计算机网络体系可以大致分为一下三种
    OSI七层模型 --->(应用层、表示层、会话层、传输层、网络层、数据链路层、物理层)
    五层模型    --->(应用层、传输层、网络层、数据链路层、物理层)
    TCP/IP四层模型  (应用层、传输层、网络层、网络接口层)
    
    应用层的任务是通过应用进程之间的交互来完成特定的网络作用，常见的应用层协议有域名系统DNS，HTTP协议等。
    表示层的主要作用是数据的表示、安全、压缩。可确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。
    会话层的主要作用是建立通信链接，保持会话过程通信链接的畅通，同步两个节点之间的对话，决定通信是否被中断以及通信中断时决定从何处重新发送。
    传输层的主要作用是负责向两台主机进程之间的通信提供数据传输服务。传输层的协议主要有传输控制协议TCP和用户数据协议UDP。
    网络层的主要作用是选择合适的网间路由和交换结点，确保数据及时送达。常见的协议有IP协议。
    数据链路层的作用是在物理层提供比特流服务的基础上，建立相邻结点之间的数据链路，通过差错控制提供数据帧（Frame）在信道上无差错的传输，并进行各电路上的动作系列。 常见的协议有SDLC、HDLC、PPP等。
    物理层的主要作用是实现相邻计算机结点之间比特流的透明传输，并尽量屏蔽掉具体传输介质和物理设备的差异。
#### 3.URI 和 URL 区别

    URI：资源标志符，主要作用是唯一标识一个资源。
    URL：资源定位符，主要作用是提供资源的路径。
#### 4.DNS是什么，DNS的工作流程是什么样的
    DNS的定义：域名系统。
    DNS是因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的去访问互联网而不用去记住能够被机器直接读取的IP地址。
    比如大家访问百度，更多地肯定是访问www.baidu.com，而不是访问112.80.248.74，因为这几乎无规则的IP地址实在太难记了。
    DNS要做的就是将www.baidu.com解析成112.80.248.74。
    
    DNS是集群式的工作方式还是 单点式的，为什么？
    集群式，如果单点式服务器，服务器如果直接宕机域名系统直接瘫痪，因特尔直接崩了。
    不光需要集群式，还需要添加缓存操作，让域名解析速度更快。
    
    工作流程：
    1.在浏览器中输入www.baidu.com域名，操作系统会先检查自己本地的hosts文件是否有这个域名的映射关系，
        如果有，就先调用这个IP地址映射，完成域名解析。
        如果hosts文件中没有，则查询本地DNS解析器缓存，如果有，则完成地址解析。
        如果本地DNS解析器缓存中没有，则去查找本地DNS服务器，如果查到，完成解析。
        如果没有，则本地服务器会向根域名服务器发起查询请求。
            根域名服务器会告诉本地域名服务器去查询哪个顶级域名服务器。
    本地域名服务器向顶级域名服务器发起查询请求，顶级域名服务器会告诉本地域名服务器去查找哪个权限域名服务器。
    本地域名服务器向权限域名服务器发起查询请求，权限域名服务器告诉本地域名服务器www.baidu.com所对应的IP地址。
    本地域名服务器告诉主机www.baidu.com所对应的IP地址。
#### 5.了解ARP协议吗?　

    ARP协议属于网络层的协议，主要作用是实现从IP地址转换为MAC地址。
    在每个主机或者路由器中都建有一个ARP缓存表，表中有IP地址及IP地址对应的MAC地址。
    先来看一下什么时IP地址和MAC地址。
        IP地址：IP地址是指互联网协议地址，IP地址是IP协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。
        MAC地址：MAC地址又称物理地址，由网络设备制造商生产时写在硬件内部，不可更改，并且每个以太网设备的MAC地址都是唯一的。
    
    ARP 工作流程
        在局域网内，主机A要向主机B发送IP数据报时，首先会在主机A的ARP缓存表中查找是否有IP地址及其对应的MAC地址，如果有，则将MAC地址写入到MAC帧的首部，并通过局域网将该MAC帧发送到MAC地址所在的主机B。
        如果主机A的ARP缓存表中没有主机B的IP地址及所对应的MAC地址，主机A会在局域网内广播发送一个ARP请求分组。局域网内的所有主机都会收到这个ARP请求分组。
        主机B在看到主机A发送的ARP请求分组中有自己的IP地址，会像主机A以单播的方式发送一个带有自己MAC地址的响应分组。
        主机A收到主机B的ARP响应分组后，会在ARP缓存表中写入主机B的IP地址及其IP地址对应的MAC地址。
        如果主机A和主机B不在同一个局域网内，即使知道主机B的MAC地址也是不能直接通信的，必须通过路由器转发到主机B的局域网才可以通过主机B的MAC地址找到主机B。并且主机A和主机B已经可以通信的情况下，主机A的ARP缓存表中寸的并不是主机B的IP地址及主机B的MAC地址，而是主机B的IP地址及该通信链路上的下一跳路由器的MAC地址。这就是上图中的源IP地址和目的IP地址一直不变，而MAC地址却随着链路的不同而改变。
        如果主机A和主机B不在同一个局域网，参考上图中的主机H1和主机H2，这时主机H1需要先广播找到路由器R1的MAC地址，再由R1广播找到路由器R2的MAC地址，最后R2广播找到主机H2的MAC地址，建立起通信链路。
#### 6.有了IP地址，为什么还要MAC地址

        简单来说，标识网络中的一台计算机，比较常用的就是IP地址和MAC地址，但计算机的IP地址可由用户自行更改，管理起来相对困难，而MAC地址不可更改，所以一般会把IP地址和MAC地址组合起来使用。具体是如何组合使用的在上面的ARP协议中已经讲的很清楚了。
        那只用MAC地址不用IP地址可不可以呢？其实也是不行的，因为在最早就是MAC地址先出现的，并且当时并不用IP地址，只用MAC地址，后来随着网络中的设备越来越多，整个路由过程越来越复杂，便出现了子网的概念。对于目的地址在其他子网的数据包，路由只需要将数据包送到那个子网即可，这个过程就是上面说的ARP协议。
        那为什么要用IP地址呢？是因为IP地址是和地域相关的，对于同一个子网上的设备，IP地址的前缀都是一样的，这样路由器通过IP地 址的前缀就知道设备在在哪个子网上了，而只用MAC地址的话，路由器则需要记住每个MAC地址在哪个子网，这需要路由器有极大的存储空间，是无法实现的。
        IP地址可以比作为地址，MAC地址为收件人，在一次通信过程中，两者是缺一不可的。
#### 7.Ping的过程

        ping是ICMP(网际控制报文协议)中的一个重要应用，ICMP是网络层的协议。
        ping的作用是测试两个主机的连通性。
        ping 工作过程：
                向目的主机发送多个ICMP回送请求报文
                根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包往返时间及丢包率。
                
#### 8. 路由器与交换机的区别
            
    所属网络模型的层级	功能
    路由器	网络层	识别IP地址并根据IP地址转发数据包，维护数据表并基于数据表进行最佳路径选择
    交换机	数据链库层	识别MAC地址并根据MAC地址转发数据帧
#### 9.TCP和UDP的区别？

        TCP和UDP是OSI模型中的运输层中的协议。
        TCP提供可靠的通信传输，而UDP则常被用于让 广播和细节控制交给应用的通信传输。
        两者的区别大致如下：
            TCP面向连接，UDP面向非连接即发送数据前不需要建立链接
            TCP提供可靠的服务（数据传输），UDP无法保证
            TCP面向字节流，UDP面向报文
            TCP数据传输慢，UDP数据传输快
            TCP提供一种面向连接的、可靠的字节流服务
            在一个TCP连接中，仅有两方进行彼此通信，因此广播和多播不能用于TCP
            TCP使用校验和，确认和重传机制来保证可靠传输
            TCP使用累积确认
            TCP使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制
            
#### 10. TCP与UDP 协议简述

        TCP协议：
            FTP：定义了文件传输协议，使用21端口。
            Telnet：一种用于远程登陆的端口，使用23端口，用户可以以自己的身份远程连接到计 算机上，可提供基于DOS模式下的通信服务。
            SMTP：邮件传送协议，用于发送邮件。服务器开放的是25号端口。
            POP3：它是和SMTP对应，POP3用于接收邮件。POP3协议所用的是110端口。
            HTTP：是从Web服务器传输超文本到本地浏览器的传送协议。
            ICMP : 因特网控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息
        UDP协议：
            NAT协议：网络地址转换接入广域网（WAN）技术，是一种将私有地址转换为合法IP地址的转换技术
            DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。
            SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很 多，无连接的服务就体现出其优势。
            TFTP(Trival File TransferProtocal)，简单文件传输协议，该协议在熟知端口69上使 用UDP服务。
            DHCP协议：动态主机配置协议，使用UDP协议工作。给内部的网络和网络服务供应商自动的 分配IP地址。
            RARP是逆地址解析协议，作用是完成从硬件地址到IP地址的映射，RARP只能用于具有广播 能力的网络。封装一个RARP的数据包里面有MAC地址， 然后广播到网络上，当服务器收到请求包后，就查找对应的MAC地址的IP地址装入到响应报文中发送给请求者。
#### 11.HTTP 与 HTTPS 的区别 
                端口             安全性                  资源消耗            是否需要证书              协议
    HTTP：       80           无加密，安全性差               较少                 no          TCP协议之上
    HTTPS       443          有加密，安全性高           由于加密资源消耗较高        yes          运行在SSL协议上，SSL在TCP协议上
#### 12.什么是对称加密与非对称加密　
    对称加密
        对称加密指加密和解密使用同一密钥，优点是运算速度快，缺点是如何安全将密钥传输给另一方。常见的对称加密算法有DES、AES等等。
    非对称加密
        非对称加密指的是加密和解密使用不同的密钥，一把公开的公钥，一把私有的私钥。公钥加密的信息只有私钥才能解密，私钥加密的信息只有公钥才能解密。优点解决了对称加密中存在的问题。缺点是运算速度较慢。常见的非对称加密算法有RSA、DSA、ECC等等。
        非对称加密的工作流程：
                A生成一对非堆成密钥，将公钥向所有人公开，B拿到A的公钥后使用A的公钥对信息加密后发送给A，经过加密的信息只有A手中的私钥能解密。
                这样B可以通过这种方式将自己的公钥加密后发送给A，两方建立起通信，可以通过对方的公钥加密要发送的信息，接收方用自己的私钥解密信息。
#### 13.常用HTTP状态码
    状态码	类别
    1XX	信息性状态码
    2XX	成功状态码
    3XX	重定向状态码
    4XX	客户端错误状态码
#### 14.HTTP协议包括哪些请求
    GET：对服务器资源的简单请求
    POST：用于发送包含用户提交数据的请求
    HEAD：类似于GET请求，不过返回的响应中没有具体内容，用于获取报头
    PUT：传说中请求文档的一个版本
    DELETE：发出一个删除指定文档的请求
    TRACE：发送一个请求副本，以跟踪其处理进程
    OPTIONS：返回所有可用的方法，检查服务器支持哪些方法
    CONNECT：用于ssl隧道的基于代理的请求
#### 15.GET和POST区别
    作用
    GET用于获取资源，POST用于传输实体主体
    参数位置
    GET的参数放在URL中，POST的参数存储在实体主体中，并且GET方法提交的请求的URL中的数据做多是2048字节，POST请求没有大小限制。
    安全性
    GET方法因为参数放在URL中，安全性相对于POST较差一些
    幂等性
    GET方法是具有幂等性的，而POST方法不具有幂等性。这里幂等性指客户端连续发出多次请求，收到的结果都是一样的.
#### 16.HTTP 1.0、HTTP 1.1及HTTP 2.0的主要区别是什么

    HTTP 1.0和HTTP 1.1的区别
    长连接
        HTTP 1.1支持长连接和请求的流水线操作。
        长连接是指不在需要每次请求都重新建立一次连接，HTTP 1.0默认使用短连接，每次请求都要重新建立一次TCP连接，资源消耗较大。
        请求的流水线操作是指客户端在收到HTTP的响应报文之前可以先发送新的请求报文，
        不支持请求的流水线操作需要等到收到HTTP的响应报文后才能继续发送新的请求报文。
    缓存处理
        在HTTP 1.0中主要使用header中的If-Modified-Since,Expires作为缓存判断的标准，
        HTTP 1.1引入了Entity tag，If-Unmodified-Since, If-Match等更多可供选择的缓存头来控制缓存策略。
    错误状态码
        在HTTP 1.1新增了24个错误状态响应码
    HOST域
        在HTTP 1.0 中认为每台服务器都会绑定唯一的IP地址，所以，请求中的URL并没有传递主机名。
        但后来一台服务器上可能存在多个虚拟机，它们共享一个IP地址，所以HTTP 1.1中请求消息和响应消息都应该支持Host域。
    带宽优化及网络连接的使用
    
    在HTTP 1.0中会存在浪费带宽的现象，
        主要是因为不支持断点续传功能，客户端只是需要某个对象的一部分
        服务端却将整个对象都传了过来。
        在HTTP 1.1中请求头引入了range头域，它支持只请求资源的某个部分，返回的状态码为206。
        
    HTTP 2.0的新特性
    
        新的二进制格式：
                HTTP 1.x的解析是基于文本，HTTP 2.0的解析采用二进制，实现方便，健壮性更好。
        多路复用：
                每一个request对应一个id，一个连接上可以有多个request，每个连接的request可以随机混在一起，
                这样接收方可以根据request的id将request归属到各自不同的服务端请求里。
        header压缩：
                在HTTP 1.x中，header携带大量信息，并且每次都需要重新发送，
                HTTP 2.0采用编码的方式减小了header的大小，
                同时通信双方各自缓存一份header fields表，避免了header的重复传输。
        服务端推送：
                客户端在请求一个资源时，会把相关资源一起发给客户端，这样客户端就不需要再次发起请求。
#### 17. Session、Cookie和Token的主要区别
    HTTP协议是无状态的，即服务器无法判断用户身份。Session和Cookie可以用来进行身份辨认。
    
    Cookie
        Cookie是保存在客户端一个小数据块，其中包含了用户信息。
        当客户端向服务端发起请求，服务端会像客户端浏览器发送一个Cookie，客户端会把Cookie存起来，
        当下次客户端再次请求服务端时，会携带上这个Cookie，服务端会通过这个Cookie来确定身份。
    Session
        Session是通过Cookie实现的，和Cookie不同的是，
        Session是存在服务端的。当客户端浏览器第一次访问服务器时，
        服务器会为浏览器创建一个sessionid，将sessionid放到Cookie中，存在客户端浏览器。
        比如浏览器访问的是购物网站，将一本《图解HTTP》放到了购物车，当浏览器再次访问服务器时，
        服务器会取出Cookie中的sessionid，并根据sessionid获取会话中的存储的信息，确认浏览器的身份是上次将《图解HTTP》放入到购物车那个用户。
    Token
        客户端在浏览器第一次访问服务端时，服务端生成的一串字符串作为Token发给客户端浏览器，
        下次浏览器在访问服务端时携带token即可无需验证用户名和密码，省下来大量的资源开销。
        
    存放位置	占用空间	安全性	应用场景
    Cookie	客户端浏览器	小	较低	一般存放配置信息
    Session	服务端	多	较高	存放较为重要的信息
#### 18.如果客户端禁止 cookie 能实现 session 还能用吗？
    可以，Session的作用是在服务端来保持状态，通过sessionid来进行确认身份，
    但sessionid一般是通过Cookie来进行传递的。如果Cooike被禁用了，可以通过在URL中传递sessionid。
#### 19.在浏览器中输⼊url地址到显示主⻚的过程
        1.对输入到浏览器的url进行DNS解析，将域名转换为IP地址。     DNS解析
        2.和目的服务器建立TCP连接                             TCP连接
        3.向目的服务器发送HTTP请求                            发送HTTP请求
        4.服务器处理请求并返回HTTP报文                         服务器处理请求并返回HTTP报文
        5.浏览器解析并渲染页面                                连接结束
#### 20.说一说TCP的三次握手,为什么要三次握手
    在TCP/IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。
    三次握手的目的是同步连接双方的序列号和确认号并交换TCP窗口大小信息
        核心思想：让双方都证实对方能发收。知道对方能收是因为收到对方的因为收到信息之 后发的回应(ACK)。
                客户端–发送带有 SYN 标志的数据包–一次握手–服务端
                服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端
                客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端
    三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。
    第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常
    第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了： 对方发送正常，自己接收正常
    第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了： 自己发送、接收正常，对方发送、接收正常
    所以三次握手就能确认双发收发功能都正常，缺一不可。
#### 21.TCP为什么四次挥手
    任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。
    当另 一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。
    举个例子：
        A 和 B 打电话，通话即将结束后，
        A 说“我没啥要说的了”，
        B回答“我知道了”，
        但是B可能还会有要说的话，A不能要求B跟着自己的节奏结束通话，
        于是B可能又巴拉巴拉说了一通，最后B说“我说完了”，A 回答“知道了”，这样通话才算结束。
        
        
#### 22.阻塞控制
    在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要 变坏。这种情况就叫拥塞。
        拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。
        拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。
        拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。
        相反，流量控制往往是点对点通信量的控制，是个端到端的问题。
        流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 
        
        TCP的拥塞控制采用了四种算法，即 慢开始 、 拥塞避免 、快重传 和 快恢复
        慢开始： 
            慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到 网络，那么可能会引起网络阻塞，
            因为现在还不知道网络的符合情况。经验表明，较好 的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗 口数值。
            cwnd初始值为1，每经过一个传播轮次，cwnd加倍。
        拥塞避免： 
            拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间 RTT就把发送放的cwnd加1.
        快重传与快恢复： 
            在TCP/IP中，快速重传和恢复（fast retransmit and recovery， FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。
            没有 FRR，如果数据包丢失了，TCP将会使用定时器来要求传输暂停。
            在暂停的这段时间内，没有新的或复制的数据包被发送。
            有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机 发送一个重复确认。
            如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢 失了，并立即重传这些丢失的数据段。
            有了 FRR，就不会因为重传时要求的暂停被耽 误。 
            当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。
            当有多个 数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。
#### 23.CDN原理
    CND 一般包含分发服务系统、负载均衡系统和管理系统
        分发服务系统：
                其基本的工作单元就是各个 Cache 服务器。负责直接响应用户请求，将内容快速分发到用户；同时还负责内容更新，保证和源站内容的同步。
                根据内容类型和服务种类的不同，分发服务系统分为多个子服务系统，
                    如：网页加速服务、流媒体加速服务、应用加速服务等。每个子服务系统都是一个分布式的服务集群，
                    由功能类似、地域接近的分布部署的 Cache 集群组成。
                在承担内容同步、更新和响应用户请求之外，
                分发服务系统还需要向上层的管理调度系统反馈各个Cache 设备的健康状况、响应情况、内容缓存状况等，
                以便管理调度系统能够根据设定的策略决定由哪个 Cache 设备来响应用户的请求。
        负载均衡系统：
                负载均衡系统是整个 CDN 系统的中枢。负责对所有的用户请求进行调度，确定提供给用户的最终访问地址。
                使用分级实现。
                最基本的两极调度体系包括：
                        全局负载均衡（GSLB）和本地负载均衡（SLB）。
                GSLB 根据用户地址和用户请求的内容，主要根据就近性原则，确定向用户服务的节点。
                        一般通过 DNS解析或者应用层重定向（Http 3XX 重定向）的方式实现。
                SLB 主要负责节点内部的负载均衡。
                        当用户请求从 GSLB 调度到 SLB 时，SLB 会根据节点内各个Cache设备的工作状况和内容分布情况等对用户请求重定向。
                        SLB 的实现有四层调度（LVS）、七层调度（Nginx）和链路负载调度等。
        管理系统：
                分为运营管理和网络管理子系统。
                网络管理系统
                        实现对 CDN 系统的设备管理、拓扑管理、链路监控和故障管理，为管理员提供对全网资源的可视化的集中管理，通常用 web 方式实现。
                运营管理
                        是对 CDN 系统的业务管理，负责处理业务层面的与外界系统交互所必须的一些收集、整理、交付工作。
                        包括用户管理、产品管理、计费管理、统计分析等。

      
#### 24.什么是socket？简述基于tcp协议的套接字通信流程。
    socket:
        可以用来实现不同虚拟机或不同计算机之间的通信。
    socket原理：
        1.客户端程序把信息发送到自己的内核区
        2.操作系统将信息通过底层网卡和网络传送到服务器端内核区
        3.信息存放在服务器端内核区，等待服务器程序进行提取
        4.服务器端程序通过recv方法进行获取
    流程：
        1). 服务器先用 socket 函数来建立一个套接字，用这个套接字完成通信的监听。 
        2). 用 bind 函数来绑定一个端口号和 IP 地址。因为本地计算机可能有多个网址和 IP，每一个 IP 和端口有多个端口。
        需要指定一个 IP 和端口进行监听。 
        3). 服务器调用 listen 函数，使服务器的这个端口和 IP 处于监听状态，等待客户机的连接。 
        4). 客户机用 socket 函数建立一个套接字，设定远程 IP 和端口。 
        5). 客户机调用 connect 函数连接远程计算机指定的端口。 
        6). 服务器用 accept 函数来接受远程计算机的连接，建立起与客户机之间的通信。 
        7). 建立连接以后，客户机用 write 函数向 socket 中写入数据。也可以用 read 函数读取服务器发送来的数据。 
        8). 服务器用 read 函数读取客户机发送来的数据，也可以用 write 函数来发送数据。 
        9). 完成通信以后，用 close 函数关闭 socket 连接。
#### 25.什么是粘包？socket 中造成粘包的原因是什么？哪些情况会发生粘包现象？
    粘包：
        粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。只有TCP有粘包现象，UDP不会。
    粘包产生原因：
        1.当连续发送数据时，由于tcp协议的nagle算法，会将较小的内容拼接成大的内容，一次性发送到服务器端，因此造成粘包
        2.当发送内容较大时，由于服务器端的recv（buffer_size）方法中的buffer_size较小，不能一次性完全接收全部内容，
          因此在下一次请求到达时，接收的内容依然是上一次没有完全接收完的内容，因此造成粘包现象。
    粘包解决方法：
        在每次使用tcp协议发送数据流时,在开头标记一个数据流长度信息,并固定该报文长度(自定义协议).
        在客户端接收数据时先接收该长度字节数据,判断客户端发送数据流长度,并只接收该长度字节数据,就可以实现拆包,完美解决tcp粘包问题.
#### 25.什么是粘包？socket 中造成粘包的原因是什么？哪些情况会发生粘包现象？
    粘包：
        粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。只有TCP有粘包现象，UDP不会。
    粘包产生原因：
        1.当连续发送数据时，由于tcp协议的nagle算法，会将较小的内容拼接成大的内容，一次性发送到服务器端，因此造成粘包
        2.当发送内容较大时，由于服务器端的recv（buffer_size）方法中的buffer_size较小，不能一次性完全接收全部内容，
          因此在下一次请求到达时，接收的内容依然是上一次没有完全接收完的内容，因此造成粘包现象。
    粘包解决方法：
        在每次使用tcp协议发送数据流时,在开头标记一个数据流长度信息,并固定该报文长度(自定义协议).
        在客户端接收数据时先接收该长度字节数据,判断客户端发送数据流长度,并只接收该长度字节数据,就可以实现拆包,完美解决tcp粘包问题.


